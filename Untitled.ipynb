{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import sys\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class S2S(object):\n",
    "\n",
    "    def __init__(self, x_len, y_len, x_vocab_size, y_vocab_size, emb_dim, num_layers, ckpt_path, lr=0.001, epochs=10000, model_name='s2s_model'):\n",
    "\n",
    "        self.x_len = x_len\n",
    "        self.y_len = y_len\n",
    "        self.ckpt_path = ckpt_path\n",
    "        self.epochs = epochs\n",
    "        self.model_name = model_name\n",
    "\n",
    "        print('x_len', x_len)\n",
    "        print('y_len', y_len)\n",
    "        print('ckpt_path', ckpt_path)\n",
    "        print('epochs', epochs)\n",
    "        print('model_name', model_name)\n",
    "        print('num_layers', num_layers)\n",
    "\n",
    "        def count_number_trainable_params():\n",
    "            tot_nb_params = 0\n",
    "            for trainable_variable in tf.trainable_variables():\n",
    "                shape = trainable_variable.get_shape() # e.g [D,F] or [W,H,C]\n",
    "                current_nb_params = get_nb_params_shape(shape)\n",
    "                tot_nb_params = tot_nb_params + current_nb_params\n",
    "            return tot_nb_params\n",
    "\n",
    "        def get_nb_params_shape(shape):\n",
    "            nb_params = 1\n",
    "            for dim in shape:\n",
    "                nb_params = nb_params*int(dim)\n",
    "            return nb_params \n",
    "\n",
    "        def __graph__():\n",
    "            tf.reset_default_graph()\n",
    "            #ulazi na enkoder - maksimalan broj reci koji je dozvoljen x_len\n",
    "            self.encoder_input = [tf.placeholder(shape=[None,], dtype=tf.float32,\n",
    "            name='einput_{}'.format(t)) for t in range(x_len)]\n",
    "\n",
    "            print('self.encoder_input', len(self.encoder_input))\n",
    "            print('self.encoder_input[0]', self.encoder_input[0])\n",
    "\n",
    "            #izlazi dekodera - maksimalan broj reci koji je dozvoljen y_len\n",
    "            self.labels = [ tf.placeholder(shape=[None,], dtype=tf.float32, \n",
    "            name='doutput_{}'.format(t)) for t in range(y_len)]\n",
    "\n",
    "            print('self.labels', len(self.labels))\n",
    "            print('self.labels[0]', self.labels[0])\n",
    "\n",
    "            #ulazi na dekoder - '_GO' + [y1, y2, y3, ..., yn-1]\n",
    "            self.decoder_input = [ tf.zeros_like(self.encoder_input[0], dtype=tf.float32, name='GO') ] + self.labels[:-1]\n",
    "            print('self.decoder_input', len(self.decoder_input))\n",
    "            print('self.decoder_input[0]', self.decoder_input[0])\n",
    "\n",
    "\n",
    "            #RNN Cell - Dropout regularizacija oko RNN celije\n",
    "            self.keep_prob = tf.placeholder(tf.float32)\n",
    "            \n",
    "            cell = [tf.nn.rnn_cell.DropoutWrapper(\n",
    "                tf.nn.rnn_cell.BasicLSTMCell(emb_dim), output_keep_prob = self.keep_prob) for i in range(num_layers)]\n",
    "\n",
    "            stacked_cells = tf.nn.rnn_cell.MultiRNNCell(cell)\n",
    "\n",
    "            with tf.variable_scope('decoder') as scope:\n",
    "                self.decode_outputs, self.decode_states = tf.contrib.legacy_seq2seq.embedding_rnn_seq2seq(\n",
    "                    self.encoder_input,\n",
    "                    self.decoder_input,\n",
    "                    stacked_cells,\n",
    "                    x_vocab_size,\n",
    "                    y_vocab_size,\n",
    "                    emb_dim\n",
    "                )\n",
    "\n",
    "                scope.reuse_variables()\n",
    "\n",
    "                self.decode_outputs_test, self.decode_states_test = tf.contrib.legacy_seq2seq.embedding_rnn_seq2seq(\n",
    "                    self.encoder_input,\n",
    "                    self.decoder_input,\n",
    "                    stacked_cells,\n",
    "                    x_vocab_size,\n",
    "                    y_vocab_size,\n",
    "                    emb_dim,\n",
    "                    feed_previous=True\n",
    "                )\n",
    "\n",
    "            #loss funkcija\n",
    "            loss_weights = [tf.ones_like(label, dtype=tf.float32) for label in self.labels]\n",
    "            self.loss = tf.contrib.legacy_seq2seq.sequence_loss(\n",
    "                self.decode_outputs,\n",
    "                self.labels,\n",
    "                loss_weights,\n",
    "                y_vocab_size\n",
    "            )\n",
    "            #tf.summary.scalar('loss', self.loss)\n",
    "\n",
    "            #optimizer\n",
    "            self.train_op = tf.train.AdamOptimizer(learning_rate=lr).minimize(self.loss)\n",
    "            #self.train_op = tf.train.Ada(learning_rate=lr).minimize(self.loss)\n",
    "\n",
    "        sys.stdout.write('Building graph...\\n')\n",
    "        __graph__()\n",
    "        #print('param num method 1:', np.sum([np.product([xi.value for xi in x.get_shape()]) for x in tf.all_variables()]))\n",
    "        #print('param num method 2:', count_number_trainable_params())\n",
    "        total_parameters = 0\n",
    "        for variable in tf.trainable_variables():\n",
    "            # shape is an array of tf.Dimension\n",
    "            shape = variable.get_shape()\n",
    "            #print('name', variable)\n",
    "            print(shape)\n",
    "            #print(len(shape))\n",
    "            variable_parameters = 1\n",
    "            for dim in shape:\n",
    "                #print('###', dim.value)\n",
    "                variable_parameters *= dim.value\n",
    "            #print(variable_parameters)\n",
    "            total_parameters += variable_parameters\n",
    "        print('param num method 3:', total_parameters)\n",
    "        sys.stdout.write('Done...\\n')\n",
    "\n",
    "    \"\"\"\n",
    "    training\n",
    "    \"\"\"\n",
    "    \n",
    "    def get_feed(self, x, y, keep_prob):\n",
    "        feed_dict = {self.encoder_input[t]: x[t] for t in range(self.x_len)}\n",
    "        feed_dict.update({self.labels[t]: y[t] for t in range(self.y_len)})\n",
    "        feed_dict[self.keep_prob] = keep_prob\n",
    "        return feed_dict\n",
    "\n",
    "    def train_batch(self, sess, train_batch_gen):\n",
    "        batchX, batchY = train_batch_gen.__next__()\n",
    "\n",
    "        feed_dict = self.get_feed(batchX, batchY, keep_prob=0.5)\n",
    "        _, loss_v = sess.run([self.train_op, self.loss], feed_dict)\n",
    "        return loss_v\n",
    "\n",
    "    def evaluate_steps(self, sess, eval_batch_gen):\n",
    "        batchX, batchY = eval_batch_gen.__next__()\n",
    "\n",
    "        feed_dict = self.get_feed(batchX, batchY, keep_prob=1.)\n",
    "        loss_v, dec_op_v = sess.run([self.loss, self.decode_outputs_test], feed_dict)\n",
    "\n",
    "        dec_op_v = np.array(dec_op_v).transpose([1, 0, 2])\n",
    "        return loss_v, dec_op_v, batchX, batchY\n",
    "\n",
    "    def eval_batches(self, sess, eval_batch_gen, num_batches):\n",
    "        losses = []\n",
    "        for i in range(num_batches):\n",
    "            loss_v, dec_op_v, batchX, batchY = self.evaluate_steps(sess, eval_batch_gen)\n",
    "            losses.append(loss_v)\n",
    "        return np.mean(losses)\n",
    "\n",
    "    def train(self, train_set, valid_set, sess=None):\n",
    "        save_every = 1000\n",
    "        saver = tf.train.Saver()\n",
    "        loss_history = []\n",
    "        loss_val_history = []\n",
    "        loss_test_history = []\n",
    "        execution_time_history = []\n",
    "        if not sess:\n",
    "            print('Pravim novu sesiju...')\n",
    "            sess = tf.Session()\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            #merged = tf.summary.merge_all()\n",
    "            summary_writer = tf.summary.FileWriter('/path/s2s', graph = sess.graph)\n",
    "            #tf.global_variables_initializer().run()\n",
    "            #sess.run([])\n",
    "            \n",
    "        sys.stdout.write('>>>Training started...\\n')\n",
    "\n",
    "        for i in range(self.epochs):\n",
    "            try:\n",
    "                start = time.time()\n",
    "                loss = self.train_batch(sess, train_set)\n",
    "                end = time.time()\n",
    "                \n",
    "                print('Loss', loss, 'at iteration', i, '/', self.epochs, 'Time -', end - start)\n",
    "\n",
    "                loss_history.append(loss)\n",
    "                if i and i%50 == 0:\n",
    "                    val_loss = self.eval_batches(sess, valid_set, 16)\n",
    "                    print('val_loss', val_loss)\n",
    "                    loss_val_history.append(val_loss)\n",
    "                    if val_loss < 3:\n",
    "                        print('Validation set loss is less than 3. Stopping...')\n",
    "                        break\n",
    "\n",
    "                if i and i%save_every == 0:\n",
    "                    saver.save(sess, self.ckpt_path + self.model_name + '.ckpt', global_step=i)\n",
    "                    val_loss = self.eval_batches(sess, valid_set, 16)\n",
    "\n",
    "                    print('Model saved after', i, 'iterations.')\n",
    "                    print('Validate loss:', val_loss)\n",
    "                    sys.stdout.flush()\n",
    "            except KeyboardInterrupt:\n",
    "                print('Interrupted by user at iteration', i)\n",
    "                plt.plot(range(len(loss_history)), loss_history, label='Funkcija greske')\n",
    "                #plt.plot(range(len(loss_val_history)), loss_val_history, label='Funkcija greske za validacioni skup')\n",
    "                plt.legend()\n",
    "                plt.show()\n",
    "\n",
    "                plt.plot(range(len(execution_time_history)), execution_time_history, label='Vreme iteracija')\n",
    "                plt.legend()\n",
    "                plt.show()\n",
    "\n",
    "                plt.plot(range(len(loss_val_history)), loss_val_history, label='Funkcija greske za validacioni skup')\n",
    "                plt.legend()\n",
    "                plt.show()\n",
    "                self.session = sess\n",
    "                return sess\n",
    "        \n",
    "        plt.plot(range(len(loss_history)), loss_history, label='Funkcija greske')\n",
    "        #plt.plot(range(len(loss_val_history)), loss_val_history, label='Funkcija greske za validacioni skup')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "        plt.plot(range(len(execution_time_history)), execution_time_history, label='Vreme iteracija')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "        plt.plot(range(len(loss_val_history)), loss_val_history, label='Funkcija greske za validacioni skup')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "        summary_writer.close()\n",
    "\n",
    "    def restore_last_session(self):\n",
    "        saver = tf.train.Saver()\n",
    "        sess = tf.Session()\n",
    "        ckpt = tf.train.get_checkpoint_state(self.ckpt_path)\n",
    "        if ckpt and ckpt.model_checkpoint_path:\n",
    "            saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "            print('Session restored')\n",
    "        return sess\n",
    "\n",
    "    def predict(self, sess, x):\n",
    "        feed_dict = {self.encoder_input[t]: x[t] for t in range(self.x_len)}\n",
    "        feed_dict[self.keep_prob] = 1.0\n",
    "        dec_op_v = sess.run(self.decode_outputs_test, feed_dict)\n",
    "\n",
    "        dec_op_v = np.array(dec_op_v).transpose([1, 0, 2])\n",
    "\n",
    "        return np.argmax(dec_op_v, axis=2)\n",
    "\n",
    "    def advance_predict(self, sess, x, axis=3):\n",
    "        feed_dict = {self.encoder_input[t]: x[t] for t in range(self.x_len)}\n",
    "        feed_dict[self.keep_prob] = 1.0\n",
    "        dec_op_v = sess.run(self.decode_outputs_test, feed_dict)\n",
    "\n",
    "        dec_op_v = np.array(dec_op_v).transpose([1, 0, 2])\n",
    "\n",
    "        if axis == 3:\n",
    "            return np.argmax(dec_op_v)\n",
    "        else:\n",
    "            return np.argmax(dec_op_v, axis=axis)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
